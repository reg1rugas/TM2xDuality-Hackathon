{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmyvGYJml6I6",
        "outputId": "89119456-5715-4ff6-81f9-0c56722c784c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. MOUNT DRIVE\n",
        "# ==========================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"scene_segmentation_test_complete\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# 2. INSTALL & IMPORTS\n",
        "# ==========================================\n",
        "!pip install -q segmentation-models-pytorch gdown\n",
        "\n",
        "import gdown\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from datetime import datetime\n",
        "import segmentation_models_pytorch as smp\n",
        "import time\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DUALITY AI CHALLENGE - COMPLETE DIAGNOSTIC TEST (WITH METRICS)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ==========================================\n",
        "# 3. DOWNLOAD DATA & MODEL\n",
        "# ==========================================\n",
        "# --- Download Test Data ---\n",
        "\n",
        "print(\"\\nDownloading Dataset...\")\n",
        "url = \"https://storage.googleapis.com/duality-public-share/Hackathons/Duality%20Hackathon/Offroad_Segmentation_testImages.zip\"\n",
        "output_zip = \"/content/test.zip\"\n",
        "\n",
        "if not os.path.exists(output_zip):\n",
        "    gdown.download(url, output_zip, quiet=False)\n",
        "    print(\"Unzipping dataset...\")\n",
        "    !unzip -q {output_zip} -d /content/data\n",
        "    print(\"‚úì Data extracted to /content/data\")\n",
        "else:\n",
        "    print(\"‚úì Dataset already exists, skipping download.\")\n",
        "\n",
        "# --- Download Model ---\n",
        "print(\"\\nDownloading Model...\")\n",
        "# REPLACE THIS WITH YOUR PATH IF ON DRIVE\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Duality_Project/checkpoints/unet-resnet34-colab-20260204-0618/best_model.pth\"\n",
        "shutil.copy(MODEL_PATH, \"/content/model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "qpmErDWImXnU",
        "outputId": "3b4af5b8-21dc-45c1-d3ff-831a3425bc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h======================================================================\n",
            "DUALITY AI CHALLENGE - COMPLETE DIAGNOSTIC TEST (WITH METRICS)\n",
            "======================================================================\n",
            "\n",
            "Downloading Dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://storage.googleapis.com/duality-public-share/Hackathons/Duality%20Hackathon/Offroad_Segmentation_testImages.zip\n",
            "To: /content/test.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.16G/1.16G [00:27<00:00, 41.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping dataset...\n",
            "‚úì Data extracted to /content/data\n",
            "\n",
            "Downloading Model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/model.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. CONFIGURATION\n",
        "# ==========================================\n",
        "class TestConfig:\n",
        "    # Paths\n",
        "    CHECKPOINT_PATH = \"/content/model.pth\"\n",
        "    TEST_IMG_DIR = \"/content/data/Offroad_Segmentation_testImages/Color_Images\"\n",
        "    TEST_MASK_DIR = \"/content/data/Offroad_Segmentation_testImages/Segmentation\" # <--- METRICS RELY ON THIS\n",
        "    OUTPUT_DIR = \"/content/test_results\"\n",
        "\n",
        "    # Model\n",
        "    ENCODER = \"resnet34\"\n",
        "    NUM_CLASSES = 10\n",
        "    IMG_HEIGHT = 544\n",
        "    IMG_WIDTH = 960\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Test settings\n",
        "    BATCH_SIZE = 8\n",
        "    NUM_WORKERS = 2\n",
        "    VISUALIZE_SAMPLES = 10\n",
        "\n",
        "    # Class info\n",
        "    CLASS_MAPPING = {\n",
        "        100: 0, 200: 1, 300: 2, 500: 3, 550: 4,\n",
        "        600: 5, 700: 6, 800: 7, 7100: 8, 10000: 9\n",
        "    }\n",
        "    CLASS_NAMES = [\"Trees\", \"Lush Bushes\", \"Dry Grass\", \"Dry Bushes\",\n",
        "                   \"Ground Clutter\", \"Flowers\", \"Logs\", \"Rocks\",\n",
        "                   \"Landscape\", \"Sky\"]\n",
        "\n",
        "    CLASS_COLORS = [\n",
        "        [34, 139, 34],   [50, 205, 50],   [154, 205, 50],  [139, 69, 19],  [160, 82, 45],\n",
        "        [255, 182, 193], [139, 90, 43],   [128, 128, 128], [210, 180, 140],[135, 206, 235]\n",
        "    ]\n",
        "\n",
        "# Create output directories\n",
        "Path(TestConfig.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(TestConfig.OUTPUT_DIR + \"/predictions\").mkdir(parents=True, exist_ok=True)\n",
        "Path(TestConfig.OUTPUT_DIR + \"/visualizations\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\n‚úì Configuration loaded\")\n",
        "print(f\"‚úì Test images: {TestConfig.TEST_IMG_DIR}\")\n",
        "print(f\"‚úì Output: {TestConfig.OUTPUT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvmYTixWmbM-",
        "outputId": "26b7cff6-263d-4c36-a466-fdd37e086513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úì Configuration loaded\n",
            "‚úì Test images: /content/data/Offroad_Segmentation_testImages/Color_Images\n",
            "‚úì Output: /content/test_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. DATA LOADER\n",
        "# ==========================================\n",
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dir):\n",
        "        self.image_dir = Path(image_dir)\n",
        "        self.image_paths = sorted(list(self.image_dir.glob(\"*.png\")) + list(self.image_dir.glob(\"*.jpg\")))\n",
        "        print(f\"\\n‚úì Found {len(self.image_paths)} test images\")\n",
        "\n",
        "    def __len__(self): return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        original_image = image.copy()\n",
        "\n",
        "        # Resize & Normalize\n",
        "        image = cv2.resize(image, (TestConfig.IMG_WIDTH, TestConfig.IMG_HEIGHT))\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        image = (image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
        "        image = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
        "\n",
        "        return image, original_image, img_path.name\n",
        "\n",
        "test_dataset = TestDataset(TestConfig.TEST_IMG_DIR)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=TestConfig.BATCH_SIZE, shuffle=False,\n",
        "    num_workers=TestConfig.NUM_WORKERS, pin_memory=True\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 6. LOAD MODEL\n",
        "# ==========================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"LOADING MODEL\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "def load_model_safely(checkpoint_path, device):\n",
        "    model = smp.Unet(\n",
        "        encoder_name=TestConfig.ENCODER,\n",
        "        encoder_weights=None,\n",
        "        classes=TestConfig.NUM_CLASSES\n",
        "    )\n",
        "    print(f\"Loading checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    except:\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['model_state_dict']\n",
        "        print(\"‚úì Extracted model_state_dict\")\n",
        "    else:\n",
        "        state_dict = checkpoint\n",
        "\n",
        "    from collections import OrderedDict\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = k.replace('module.', '')\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    model.load_state_dict(new_state_dict, strict=False)\n",
        "    print(\"‚úì Weights loaded (non-strict mode)\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Model Stats\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\nüìä Model Information:\")\n",
        "    print(f\"  ‚Ä¢ Architecture: UNet-{TestConfig.ENCODER}\")\n",
        "    print(f\"  ‚Ä¢ Total parameters: {total_params:,}\")\n",
        "    print(f\"  ‚Ä¢ Model size: {total_params * 4 / (1024**2):.2f} MB (FP32)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "model = load_model_safely(TestConfig.CHECKPOINT_PATH, TestConfig.DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sajP1Q9mmgib",
        "outputId": "b10630dd-ff44-45d8-8f31-36afe5209051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úì Found 1002 test images\n",
            "\n",
            "======================================================================\n",
            "LOADING MODEL\n",
            "======================================================================\n",
            "Loading checkpoint: /content/model.pth\n",
            "‚úì Weights loaded (non-strict mode)\n",
            "\n",
            "üìä Model Information:\n",
            "  ‚Ä¢ Architecture: UNet-resnet34\n",
            "  ‚Ä¢ Total parameters: 24,437,674\n",
            "  ‚Ä¢ Model size: 93.22 MB (FP32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 7. LATENCY CHECK (FPS)\n",
        "# ==========================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"QUICK LATENCY CHECK\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Warmup\n",
        "print(\"Warming up...\")\n",
        "dummy_input = torch.randn(1, 3, TestConfig.IMG_HEIGHT, TestConfig.IMG_WIDTH).to(TestConfig.DEVICE)\n",
        "with torch.no_grad():\n",
        "    for _ in range(10): _ = model(dummy_input)\n",
        "\n",
        "if TestConfig.DEVICE == 'cuda': torch.cuda.synchronize()\n",
        "\n",
        "# Measure\n",
        "print(\"Measuring latency (100 runs)...\")\n",
        "times = []\n",
        "with torch.no_grad():\n",
        "    for _ in tqdm(range(100)):\n",
        "        if TestConfig.DEVICE == 'cuda': torch.cuda.synchronize()\n",
        "        start = time.perf_counter()\n",
        "        _ = model(dummy_input)\n",
        "        if TestConfig.DEVICE == 'cuda': torch.cuda.synchronize()\n",
        "        times.append(time.perf_counter() - start)\n",
        "\n",
        "avg_time_ms = np.mean(times) * 1000\n",
        "fps = 1000 / avg_time_ms\n",
        "\n",
        "print(f\"\\n‚ö° Results:\")\n",
        "print(f\"  ‚Ä¢ Average latency: {avg_time_ms:.2f} ms\")\n",
        "print(f\"  ‚Ä¢ FPS: {fps:.2f}\")\n",
        "print(f\"  ‚Ä¢ Real-time capable (30 FPS): {'‚úÖ Yes' if fps >= 30 else '‚ùå No'}\")\n",
        "\n",
        "if TestConfig.DEVICE == 'cuda':\n",
        "    mem_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "    print(f\"  ‚Ä¢ GPU memory: {mem_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s3ydvIkmjbd",
        "outputId": "ccf23b56-2ae2-4fe4-b823-f3d82bf7b870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "QUICK LATENCY CHECK\n",
            "======================================================================\n",
            "\n",
            "Warming up...\n",
            "Measuring latency (100 runs)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 29.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ö° Results:\n",
            "  ‚Ä¢ Average latency: 33.48 ms\n",
            "  ‚Ä¢ FPS: 29.87\n",
            "  ‚Ä¢ Real-time capable (30 FPS): ‚ùå No\n",
            "  ‚Ä¢ GPU memory: 291.38 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 8. INFERENCE\n",
        "# ==========================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"RUNNING INFERENCE\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "predictions = []\n",
        "original_images = []\n",
        "filenames = []\n",
        "class_pixel_counts = {i: 0 for i in range(TestConfig.NUM_CLASSES)}\n",
        "total_pixels = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, orig_imgs, names in tqdm(test_loader, desc=\"Inference\"):\n",
        "        images = images.to(TestConfig.DEVICE)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "\n",
        "        for pred, orig_img, name in zip(preds, orig_imgs, names):\n",
        "            predictions.append(pred)\n",
        "            original_images.append(orig_img.numpy())\n",
        "            filenames.append(name)\n",
        "\n",
        "            # Update Statistics\n",
        "            unique, counts = np.unique(pred, return_counts=True)\n",
        "            for cls, count in zip(unique, counts):\n",
        "                class_pixel_counts[cls] += count\n",
        "                total_pixels += count\n",
        "\n",
        "print(f\"\\n‚úì Generated {len(predictions)} predictions\")\n",
        "\n",
        "# ==========================================\n",
        "# 9. CALCULATING METRICS (RESTORED!)\n",
        "# ==========================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"CALCULATING ACCURACY & IoU\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "test_mask_dir = Path(TestConfig.TEST_MASK_DIR)\n",
        "\n",
        "if test_mask_dir.exists():\n",
        "    print(f\"‚úì Ground truth found at: {test_mask_dir}\")\n",
        "\n",
        "    gt_masks = []\n",
        "    valid_pairs = []\n",
        "\n",
        "    print(\"Loading Ground Truth...\")\n",
        "    for idx, filename in enumerate(tqdm(filenames)):\n",
        "        mask_path = test_mask_dir / filename\n",
        "        if mask_path.exists():\n",
        "            gt_mask = cv2.imread(str(mask_path), cv2.IMREAD_UNCHANGED)\n",
        "            pred = predictions[idx]\n",
        "\n",
        "            # FIX 1: Resize GT to match prediction size\n",
        "            if gt_mask.shape != pred.shape:\n",
        "                gt_mask = cv2.resize(gt_mask, (pred.shape[1], pred.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            # FIX 2: Remap GT values to 0-9\n",
        "            gt_remapped = np.zeros(pred.shape, dtype=np.int64)\n",
        "            for old_id, new_id in TestConfig.CLASS_MAPPING.items():\n",
        "                gt_remapped[gt_mask == old_id] = new_id\n",
        "\n",
        "            gt_masks.append(gt_remapped)\n",
        "            valid_pairs.append(idx)\n",
        "\n",
        "    print(f\"‚úì Found masks for {len(valid_pairs)}/{len(predictions)} images\")\n",
        "\n",
        "    # --- IoU Calculation Logic ---\n",
        "    print(\"Computing metrics...\")\n",
        "    all_ious = []\n",
        "    all_accuracies = []\n",
        "    class_totals = np.zeros(TestConfig.NUM_CLASSES)\n",
        "\n",
        "    for idx in tqdm(valid_pairs):\n",
        "        pred = predictions[idx]\n",
        "        gt = gt_masks[idx]\n",
        "\n",
        "        # Pixel Accuracy\n",
        "        acc = (pred == gt).sum() / pred.size\n",
        "        all_accuracies.append(acc)\n",
        "\n",
        "        # IoU per class\n",
        "        ious = np.full(TestConfig.NUM_CLASSES, np.nan)\n",
        "        for cls in range(TestConfig.NUM_CLASSES):\n",
        "            pred_mask = (pred == cls)\n",
        "            target_mask = (gt == cls)\n",
        "\n",
        "            if target_mask.sum() > 0:\n",
        "                class_totals[cls] += 1\n",
        "                intersection = np.logical_and(pred_mask, target_mask).sum()\n",
        "                union = np.logical_or(pred_mask, target_mask).sum()\n",
        "                ious[cls] = intersection / union if union > 0 else 0.0\n",
        "            else:\n",
        "                ious[cls] = np.nan\n",
        "        all_ious.append(ious)\n",
        "\n",
        "    # --- Aggregation ---\n",
        "    all_ious = np.array(all_ious)\n",
        "    mean_ious = np.nanmean(all_ious, axis=0)\n",
        "\n",
        "    # Calculate Mean IoU only for classes present\n",
        "    valid_class_ious = mean_ious[~np.isnan(mean_ious)]\n",
        "    mean_iou = np.mean(valid_class_ious) if len(valid_class_ious) > 0 else 0.0\n",
        "    mean_accuracy = np.mean(all_accuracies)\n",
        "\n",
        "    # --- PRINT RESULTS ---\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TEST SET METRICS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nüìä Overall Metrics:\")\n",
        "    print(f\"  ‚Ä¢ Mean IoU:       {mean_iou:.4f}\")\n",
        "    print(f\"  ‚Ä¢ Pixel Accuracy: {mean_accuracy:.4f}\")\n",
        "\n",
        "    print(f\"\\nüìà Per-Class Metrics:\")\n",
        "    print(\"-\" * 95)\n",
        "    print(f\"{'Class':<15} {'IoU':>8} {'Count':>10} {'Status':>15}\")\n",
        "    print(\"-\" * 95)\n",
        "\n",
        "    for i, class_name in enumerate(TestConfig.CLASS_NAMES):\n",
        "        iou = mean_ious[i]\n",
        "        count = int(class_totals[i])\n",
        "\n",
        "        if np.isnan(iou) or count == 0:\n",
        "            iou_str = \"N/A\"\n",
        "            status = \"Not in test\"\n",
        "        else:\n",
        "            iou_str = f\"{iou:.4f}\"\n",
        "            status = \"Present\"\n",
        "\n",
        "        print(f\"{class_name:<15} {iou_str:>8} {count:>10} {status:>15}\")\n",
        "    print(\"-\" * 95)\n",
        "\n",
        "    # Save Metrics JSON\n",
        "    test_metrics = {\n",
        "        \"mean_iou\": float(mean_iou),\n",
        "        \"pixel_accuracy\": float(mean_accuracy),\n",
        "        \"per_class\": {name: float(mean_ious[i]) if not np.isnan(mean_ious[i]) else None for i, name in enumerate(TestConfig.CLASS_NAMES)}\n",
        "    }\n",
        "    with open(f\"{TestConfig.OUTPUT_DIR}/test_metrics.json\", 'w') as f:\n",
        "        json.dump(test_metrics, f, indent=2)\n",
        "\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Ground truth folder not found: {test_mask_dir}\")\n",
        "    print(\"Skipping metric calculation (Visualizations only).\")\n",
        "\n",
        "# ==========================================\n",
        "# 10. SAVING PREDICTIONS\n",
        "# ==========================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SAVING PREDICTIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "REVERSE_MAPPING = {v: k for k, v in TestConfig.CLASS_MAPPING.items()}\n",
        "\n",
        "for pred, filename in tqdm(zip(predictions, filenames), total=len(predictions), desc=\"Saving PNGs\"):\n",
        "    pred_mask = np.zeros_like(pred, dtype=np.uint16)\n",
        "    for class_idx, original_id in REVERSE_MAPPING.items():\n",
        "        pred_mask[pred == class_idx] = original_id\n",
        "\n",
        "    save_path = Path(TestConfig.OUTPUT_DIR) / \"predictions\" / filename\n",
        "    cv2.imwrite(str(save_path), pred_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPjGC9yXmu3f",
        "outputId": "8bf3137c-de6f-4ffc-8b58-288b67ce3aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "RUNNING INFERENCE\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:58<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úì Generated 1002 predictions\n",
            "\n",
            "======================================================================\n",
            "CALCULATING ACCURACY & IoU\n",
            "======================================================================\n",
            "\n",
            "‚úì Ground truth found at: /content/data/Offroad_Segmentation_testImages/Segmentation\n",
            "Loading Ground Truth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1002/1002 [00:13<00:00, 75.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Found masks for 1002/1002 images\n",
            "Computing metrics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1002/1002 [00:16<00:00, 59.26it/s]\n",
            "/tmp/ipython-input-2772768329.py:100: RuntimeWarning: Mean of empty slice\n",
            "  mean_ious = np.nanmean(all_ious, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TEST SET METRICS\n",
            "======================================================================\n",
            "\n",
            "üìä Overall Metrics:\n",
            "  ‚Ä¢ Mean IoU:       0.4172\n",
            "  ‚Ä¢ Pixel Accuracy: 0.6168\n",
            "\n",
            "üìà Per-Class Metrics:\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Class                IoU      Count          Status\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Trees             0.4808        986         Present\n",
            "Lush Bushes       0.0035        668         Present\n",
            "Dry Grass         0.3596       1002         Present\n",
            "Dry Bushes        0.3806       1002         Present\n",
            "Ground Clutter       N/A          0     Not in test\n",
            "Flowers              N/A          0     Not in test\n",
            "Logs                 N/A          0     Not in test\n",
            "Rocks             0.0768       1002         Present\n",
            "Landscape         0.6403       1002         Present\n",
            "Sky               0.9786       1002         Present\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "SAVING PREDICTIONS\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving PNGs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1002/1002 [00:12<00:00, 79.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 11. VISUALIZATIONS & CHARTS\n",
        "# ==========================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "def mask_to_rgb(mask):\n",
        "    h, w = mask.shape\n",
        "    rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    for i, color in enumerate(TestConfig.CLASS_COLORS):\n",
        "        rgb[mask == i] = color\n",
        "    return rgb\n",
        "\n",
        "# 1. Image Visualizations\n",
        "np.random.seed(42)\n",
        "viz_indices = np.random.choice(len(predictions), min(TestConfig.VISUALIZE_SAMPLES, len(predictions)), replace=False)\n",
        "\n",
        "for idx in tqdm(viz_indices, desc=\"Creating Overlays\"):\n",
        "    pred = predictions[idx]\n",
        "    orig_img = original_images[idx]\n",
        "    filename = filenames[idx]\n",
        "\n",
        "    pred_resized = cv2.resize(pred.astype(np.uint8), (orig_img.shape[1], orig_img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "    mask_rgb = mask_to_rgb(pred_resized)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    axes[0].imshow(orig_img); axes[0].set_title(\"Original\", fontsize=14)\n",
        "    axes[1].imshow(mask_rgb); axes[1].set_title(\"Prediction\", fontsize=14)\n",
        "    axes[2].imshow(cv2.addWeighted(orig_img, 0.6, mask_rgb, 0.4, 0)); axes[2].set_title(\"Overlay\", fontsize=14)\n",
        "    for ax in axes: ax.axis('off')\n",
        "\n",
        "    patches = [mpatches.Patch(color=np.array(c)/255., label=n) for c, n in zip(TestConfig.CLASS_COLORS, TestConfig.CLASS_NAMES)]\n",
        "    fig.legend(handles=patches, loc='lower center', ncol=5, fontsize=10)\n",
        "    plt.savefig(f\"{TestConfig.OUTPUT_DIR}/visualizations/viz_{filename}\", bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# 2. Summary Bar Chart\n",
        "print(\"\\nCreating Summary Chart...\")\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "class_pixel_counts = {i: 0 for i in range(TestConfig.NUM_CLASSES)}\n",
        "total_pixels = 0\n",
        "for pred in predictions:\n",
        "    unique, counts = np.unique(pred, return_counts=True)\n",
        "    for cls, count in zip(unique, counts):\n",
        "        class_pixel_counts[cls] += count\n",
        "        total_pixels += count\n",
        "\n",
        "percentages = [(class_pixel_counts[i] / total_pixels) * 100 for i in range(TestConfig.NUM_CLASSES)]\n",
        "colors_normalized = [np.array(color)/255. for color in TestConfig.CLASS_COLORS]\n",
        "\n",
        "bars = ax.bar(TestConfig.CLASS_NAMES, percentages, color=colors_normalized, edgecolor='black')\n",
        "ax.set_ylabel('Percentage of Pixels (%)'); ax.set_title('Class Distribution in Test Set Predictions')\n",
        "plt.xticks(rotation=45, ha='right'); plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar, pct in zip(bars, percentages):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height(), f'{pct:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{TestConfig.OUTPUT_DIR}/class_distribution_summary.png\", dpi=150)\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUFYmaKFnBNR",
        "outputId": "7dcac660-5ebf-4d10-b7a8-2d682efd0cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "GENERATING VISUALIZATIONS\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating Overlays: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating Summary Chart...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 12. ZIP & DOWNLOAD\n",
        "# ==========================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ZIPPING RESULTS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "shutil.make_archive(\"/content/test_results\", 'zip', TestConfig.OUTPUT_DIR)\n",
        "print(f\"‚úì Done! Download 'test_results.zip' from the files tab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHJXMLsQnFZ6",
        "outputId": "fb9df777-0175-4700-be74-35e9707dfddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ZIPPING RESULTS\n",
            "======================================================================\n",
            "\n",
            "‚úì Done! Download 'test_results.zip' from the files tab.\n"
          ]
        }
      ]
    }
  ]
}